{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-21046d235dbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from statistics import mode\n",
    "from utils.datasets import get_labels\n",
    "# from utils.inference import detect_faces\n",
    "from utils.inference import draw_text\n",
    "from utils.inference import draw_bounding_box\n",
    "from utils.inference import apply_offsets\n",
    "from utils.inference import load_detection_model\n",
    "from utils.preprocessor import preprocess_input\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mtcnn import MTCNN\n",
    "import time\n",
    "# USE_WEBCAM = True # If false, loads video file source\n",
    "detector = MTCNN(min_face_size=10)\n",
    "# parameters for loading data and images\n",
    "emotion_model_path = './models/emotion_model.hdf5'\n",
    "emotion_labels = get_labels('fer2013')\n",
    "\n",
    "# hyper-parameters for bounding boxes shape\n",
    "frame_window = 25\n",
    "emotion_offsets = (20, 40)\n",
    "\n",
    "# loading models\n",
    "# face_cascade = cv2.CascadeClassifier('./models/haarcascade_frontalface_default.xml')\n",
    "emotion_classifier = load_model(emotion_model_path)\n",
    "\n",
    "# getting input model shapes for inference\n",
    "emotion_target_size = emotion_classifier.input_shape[1:3] # why ?????\n",
    "print(emotion_target_size)\n",
    "# starting lists for calculating modes\n",
    "emotion_window = []\n",
    "\n",
    "# starting video streaming\n",
    "\n",
    "#cv2.namedWindow('window_frame')\n",
    "#video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "'''\n",
    "# Select video or webcam feed\n",
    "cap = None\n",
    "if (USE_WEBCAM == True):\n",
    "    cap = cv2.VideoCapture(0) # Webcam source\n",
    "else:\n",
    "    cap = cv2.VideoCapture('./demo/dinner.mp4') # Video file source\n",
    "'''\n",
    "def get_namefile_detail():\n",
    "    osname = '' #os.getcwd()\n",
    "    list_emotion = os.listdir('/Volumes/NO NAME/emotions/jaffedbase')#'EmotionSet')#'/Volumes/NO NAME/FERG_DB_256/aia')\n",
    "    if '._.DS_Store' in list_emotion:\n",
    "        list_emotion.remove('._.DS_Store')\n",
    "    '''\n",
    "    osname+='/Volumes/NO NAME/emotions/jaffedbase'#'EmotionSet'#'/Volumes/NO NAME/FERG_DB_256/aia'\n",
    "    osname_const = osname\n",
    "    count = 0 \n",
    "    list_emotion_images_namefile = []\n",
    "    for emotion in  list_emotion:\n",
    "        osname += '/' +emotion\n",
    "        \n",
    "        list_images = os.listdir(osname)\n",
    "        \n",
    "        if '.DS_Store' in list_images:\n",
    "            list_images.remove('.DS_Store')\n",
    "        count+=len(list_images)\n",
    "\n",
    "        # for f in list_images :\n",
    "        #     list_emotion_images_namefile.append(osname+'/'+f)\n",
    "        # osname = osname_const\n",
    "    '''\n",
    "    #result_real = list_emotion_images_namefile[0].split('/')[1]\n",
    "    print(list_emotion)\n",
    "    return list_emotion\n",
    "    #return list_emotion_images_namefile\n",
    "happy = 0\n",
    "neutral = 0\n",
    "sad = 0\n",
    "temp = 0\n",
    "class TestScale:\n",
    "    global neutral,happy,sad\n",
    "    global temp\n",
    "    def __init__(self,namefile):\n",
    "        self.namefile = namefile\n",
    "    def emotion_detection(self):\n",
    "        \n",
    "        global temp\n",
    "        frame = cv2.imread(str_)\n",
    "        print(frame)\n",
    "        #gray_image = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "        rgb_image = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        #MTCNN\n",
    "\n",
    "        faces = detector.detect_faces(frame)\n",
    "        faces = [face['box'] for face in faces]\n",
    "        \n",
    "        print([faces])\n",
    "        # exit()\n",
    "        \n",
    "        ''' HAARCASCADE\n",
    "        #faces = face_cascade.detectMultiScale(gray_image, scaleFactor=1.1,minNeighbors=1, minSize=(30,30),flags = cv2.CASCADE_SCALE_IMAGE)\n",
    "        # print(faces)\n",
    "        '''\n",
    "        for face_coordinates in faces: #if 1 :\n",
    "            x1, x2, y1, y2 = apply_offsets(face_coordinates, emotion_offsets)\n",
    "            gray_face = frame[y1:y2, x1:x2]\n",
    "            # print(gray_face)\n",
    "            try:\n",
    "                gray_face = cv2.resize(gray_face, (emotion_target_size)) #interpolation : Linear\n",
    "            except:\n",
    "                #pass\n",
    "                continue\n",
    "            # print(gray_face)\n",
    "            # print(gray_face.shape)\n",
    "            gray_face = preprocess_input(gray_face, True)\n",
    "            # print(gray_face)\n",
    "            gray_face = np.expand_dims(gray_face, 0) #axis = 0\n",
    "            # print(gray_face.shape)\n",
    "            gray_face= np.expand_dims(gray_face,-1) #axis = -1\n",
    "            # print(gray_face.shape)\n",
    "            emotion_prediction = emotion_classifier.predict(gray_face)\n",
    "            \n",
    "            emotion_prediction = emotion_prediction.tolist()\n",
    "            # print(emotion_prediction[0])\n",
    "            # emotion_prediction[0][0:3]=[0,0,0] #7\n",
    "            # emotion_prediction[0][5]=0 #7\n",
    "            # print(emotion_prediction.shape)\n",
    "            emotion_prediction = np.asarray(emotion_prediction)\n",
    "            # print(emotion_prediction)\n",
    "            emotion_probability = np.max(emotion_prediction)\n",
    "            # print(emotion_probability)\n",
    "            emotion_label_arg = np.argmax(emotion_prediction)\n",
    "            # print(emotion_label_arg) # emotion numbers dict\n",
    "            emotion_text = emotion_labels[emotion_label_arg]\n",
    "            emotion_window.append(emotion_text)\n",
    "            print(emotion_text)\n",
    "\n",
    "            if len(emotion_window) > frame_window:\n",
    "                emotion_window.pop(0)\n",
    "            try:\n",
    "                emotion_mode = mode(emotion_window)\n",
    "            except:\n",
    "                pass\n",
    "            if emotion_text:\n",
    "                temp+=1\n",
    "                return emotion_text\n",
    "            else:\n",
    "                pass\n",
    "            # return emotion_mode\n",
    "        \n",
    "    def result_real(self):\n",
    "        str_ = self.namefile\n",
    "        val_0 = str_.split('/')[5]\n",
    "        val = val_0.split('.')[1][:3]\n",
    "        print(val)\n",
    "        if val ==\"NE\":\n",
    "            neutral +=1\n",
    "            return \"neutral\"\n",
    "        elif val ==\"HA\":\n",
    "            happy +=1\n",
    "            return \"happy\"\n",
    "        elif val ==\"SA\":\n",
    "            sad+=1\n",
    "            return \"sad\"\n",
    "        else:\n",
    "            return val\n",
    "        #return str_.split('.')[1][:3]\n",
    "        #return str_.split('/')[5]\n",
    " #get_namefile_detail()\n",
    "#for i in list_name:\n",
    "    #print(i)\n",
    "a = 0\n",
    "\n",
    "'''\n",
    "happy = len(os.listdir('/Volumes/NO NAME/emotions/jaffedbase'))#'EmotionSet/happy'))#'/Volumes/NO NAME/FERG_DB_256/aia/happy'))\n",
    "neutral = len(os.listdir('/Volumes/NO NAME/FERG_DB_256/aia/surprise')) #'EmotionSet/neutral'))#'/Volumes/NO NAME/FERG_DB_256/aia/neutral'))\n",
    "# surprise = 40\n",
    "sad = len(os.listdir('/Volumes/NO NAME/FERG_DB_256/aia/sad'))#'EmotionSet/sad'))#'/Volumes/NO NAME/FERG_DB_256/aia/sad'))\n",
    "'''\n",
    "true_happy = []\n",
    "true_neutral = []\n",
    "# true_surprise = []\n",
    "true_sad = []\n",
    "time_ = []\n",
    "\n",
    "link = \"/Volumes/NO NAME/emotions/jaffedbase/\"\n",
    "list_image = os.listdir(link)\n",
    "list_image.remove(\"._.DS_Store\")\n",
    "list_image.remove(\".DS_Store\")\n",
    "for i in list_image:\n",
    "    if \"._\" in i:\n",
    "        i=i[2:]\n",
    "    link+=i\n",
    "    print(link)\n",
    "    try:\n",
    "        \n",
    "        TEST = TestScale(str(link))\n",
    "        \n",
    "        # print(TEST.result_real())\n",
    "        b=time.time()\n",
    "        TEST.emotion_detection()\n",
    "        time_.append((time.time()-b))\n",
    "        if TEST.emotion_detection() == TEST.result_real():\n",
    "            if TEST.result_real() == \"happy\":\n",
    "                true_happy.append(1)\n",
    "            elif TEST.result_real() == \"sad\":\n",
    "                true_sad.append(1)\n",
    "            elif TEST.result_real() == \"neutral\":\n",
    "                true_neutral.append(1)\n",
    "            # elif TEST.result_real() == \"surprise\":\n",
    "            #     true_surprise.append(1)\n",
    "\n",
    "        a+=1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    fr = cv2.imread(link)\n",
    "    cv2.imshow('fr'+i,fr)\n",
    "    link = \"/Volumes/NO NAME/emotions/jaffedbase/\"\n",
    "'''\n",
    "for i in list_name :\n",
    "    #print(i)\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        TEST = TestScale(str(i))\n",
    "        \n",
    "        # print(TEST.result_real())\n",
    "        b=time.time()\n",
    "        TEST.emotion_detection()\n",
    "        time_.append((time.time()-b))\n",
    "        if TEST.emotion_detection() == TEST.result_real():\n",
    "            if TEST.result_real() == \"happy\":\n",
    "                true_happy.append(1)\n",
    "            elif TEST.result_real() == \"sad\":\n",
    "                true_sad.append(1)\n",
    "            elif TEST.result_real() == \"neutral\":\n",
    "                true_neutral.append(1)\n",
    "            # elif TEST.result_real() == \"surprise\":\n",
    "            #     true_surprise.append(1)\n",
    "\n",
    "        a+=1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "'''\n",
    "print(len(true_neutral),neutral)\n",
    "print(a,temp)\n",
    "print('Happy : scale = ',len(true_happy)/happy)\n",
    "print('sad : scale = ',len(true_sad)/sad)\n",
    "# print('surprise : scale = ',len(true_surprise)/surprise)\n",
    "print('neutral : scale = ',len(true_neutral)/neutral)\n",
    "\n",
    "divisions = ['happy','neutral','sad']\n",
    "division_average_marks = [len(true_happy)/happy*100,len(true_neutral)/neutral*100,len(true_sad)/sad*100]\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(divisions,division_average_marks,color = 'grey')\n",
    "plt.title(\"Bar Emotion scale\")\n",
    "plt.ylim(0,100)\n",
    "plt.xlabel(\"Emotions\")\n",
    "plt.ylabel(\"Mark : (%)\")\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%s' % str(height)[:5],\n",
    "                ha='center', va='bottom')\n",
    "print(max(time_),min(time_))\n",
    "autolabel(rects1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (4.1.2.30)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages (from opencv-python) (1.16.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.7/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c8ec22b3e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
